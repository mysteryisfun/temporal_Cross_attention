{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7101010",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Face Extraction Pipeline\n",
    "\n",
    "## Cross-Attention CNN Personality Trait Prediction Project\n",
    "\n",
    "This notebook extracts faces from existing frame data using GPU-accelerated MTCNN face detection, then computes optical flow sequences for the Cross-Attention CNN model.\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Verify GPU Support** - Ensure TensorFlow has GPU access\n",
    "2. **Extract Faces** - Use MTCNN on existing frames (82,620 frames from 960 videos)\n",
    "3. **Compute Optical Flow** - Generate flow sequences between consecutive face frames\n",
    "4. **Progress Tracking** - Monitor extraction progress and save results\n",
    "\n",
    "### Data Structure:\n",
    "- **Input**: `data/processed/frames/` (existing frame extractions)\n",
    "- **Output**: `data/processed/faces/` and `data/processed/optical_flow/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30c28cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "OpenCV version: 4.10.0\n",
      "NumPy version: 1.24.0\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import MTCNN for face detection\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b75eb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” GPU Configuration Check\n",
      "==================================================\n",
      "Physical GPUs: 1\n",
      "Logical GPUs: 1\n",
      "âœ… GPU Support Available!\n",
      "   GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "âš ï¸ Memory growth setup error: Physical devices cannot be modified after being initialized\n",
      "\n",
      "ðŸ§ª Test operation result: [[ 7. 10.]\n",
      " [15. 22.]]\n",
      "Device used: /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU Availability and Configuration\n",
    "print(\"ðŸ” GPU Configuration Check\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# List physical GPU devices\n",
    "physical_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "\n",
    "print(f\"Physical GPUs: {len(physical_gpus)}\")\n",
    "print(f\"Logical GPUs: {len(logical_gpus)}\")\n",
    "\n",
    "if physical_gpus:\n",
    "    print(\"âœ… GPU Support Available!\")\n",
    "    for i, gpu in enumerate(physical_gpus):\n",
    "        print(f\"   GPU {i}: {gpu}\")\n",
    "    \n",
    "    # Enable memory growth to prevent TensorFlow from allocating all GPU memory\n",
    "    try:\n",
    "        for gpu in physical_gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"âœ… GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸ Memory growth setup error: {e}\")\n",
    "else:\n",
    "    print(\"âŒ No GPU detected - using CPU\")\n",
    "\n",
    "# Test GPU with a simple operation\n",
    "with tf.device('/GPU:0' if physical_gpus else '/CPU:0'):\n",
    "    test_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    result = tf.matmul(test_tensor, test_tensor)\n",
    "    print(f\"\\nðŸ§ª Test operation result: {result.numpy()}\")\n",
    "    print(f\"Device used: {result.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23cce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Initializing MTCNN Face Detector\n",
      "==================================================\n",
      "âœ… MTCNN detector initialized successfully\n",
      "\n",
      "ðŸ“ Output directories created:\n",
      "   Faces: data/processed/faces\n",
      "   Optical Flow: data/processed/optical_flow\n",
      "\n",
      "ðŸ” MTCNN Configuration:\n",
      "   Available attributes: ['detect_faces', 'device', 'get_stage', 'predict', 'stages']\n"
     ]
    }
   ],
   "source": [
    "# Initialize MTCNN Face Detector\n",
    "print(\"ðŸ¤– Initializing MTCNN Face Detector\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize MTCNN with default settings first, then optimize\n",
    "try:\n",
    "    # Try with basic parameters\n",
    "    detector = MTCNN()\n",
    "    print(\"âœ… MTCNN detector initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error initializing MTCNN: {e}\")\n",
    "    # Fallback to basic initialization\n",
    "    from mtcnn import MTCNN\n",
    "    detector = MTCNN()\n",
    "    print(\"âœ… MTCNN detector initialized with fallback\")\n",
    "\n",
    "# Configuration\n",
    "target_face_size = (224, 224)\n",
    "frames_base_dir = 'data/processed/frames'\n",
    "faces_base_dir = 'data/processed/faces'\n",
    "flow_base_dir = 'data/processed/optical_flow'\n",
    "\n",
    "# Create output directories\n",
    "Path(faces_base_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(flow_base_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nðŸ“ Output directories created:\")\n",
    "print(f\"   Faces: {faces_base_dir}\")\n",
    "print(f\"   Optical Flow: {flow_base_dir}\")\n",
    "\n",
    "# Print MTCNN attributes to see available parameters\n",
    "print(f\"\\nðŸ” MTCNN Configuration:\")\n",
    "print(f\"   Available attributes: {[attr for attr in dir(detector) if not attr.startswith('_')][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e499dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Data Structure Analysis\n",
      "==================================================\n",
      "Found 12 training directories:\n",
      "   training80_01: 80 videos, 6971 frames\n",
      "   training80_02: 80 videos, 6874 frames\n",
      "   training80_03: 80 videos, 6666 frames\n",
      "   training80_04: 80 videos, 6858 frames\n",
      "   training80_05: 80 videos, 6971 frames\n",
      "   training80_06: 80 videos, 6861 frames\n",
      "   training80_07: 80 videos, 6897 frames\n",
      "   training80_08: 80 videos, 7060 frames\n",
      "   training80_09: 80 videos, 6920 frames\n",
      "   training80_10: 80 videos, 6738 frames\n",
      "   training80_11: 80 videos, 6959 frames\n",
      "   training80_12: 80 videos, 6845 frames\n",
      "\n",
      "ðŸ“ˆ Summary:\n",
      "   Total training directories: 12\n",
      "   Total videos: 960\n",
      "   Total frames: 82,620\n"
     ]
    }
   ],
   "source": [
    "# Analyze Current Data Structure\n",
    "print(\"ðŸ“Š Data Structure Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check frames directory structure\n",
    "if os.path.exists(frames_base_dir):\n",
    "    training_dirs = sorted([d for d in os.listdir(frames_base_dir) \n",
    "                           if os.path.isdir(os.path.join(frames_base_dir, d))])\n",
    "    \n",
    "    total_videos = 0\n",
    "    total_frames = 0\n",
    "    frame_stats = {}\n",
    "    \n",
    "    print(f\"Found {len(training_dirs)} training directories:\")\n",
    "    \n",
    "    for training_dir in training_dirs:\n",
    "        training_path = os.path.join(frames_base_dir, training_dir)\n",
    "        video_dirs = [d for d in os.listdir(training_path) \n",
    "                     if os.path.isdir(os.path.join(training_path, d))]\n",
    "        \n",
    "        dir_frames = 0\n",
    "        for video_dir in video_dirs:\n",
    "            video_path = os.path.join(training_path, video_dir)\n",
    "            frame_files = [f for f in os.listdir(video_path) if f.endswith('.jpg')]\n",
    "            dir_frames += len(frame_files)\n",
    "        \n",
    "        total_videos += len(video_dirs)\n",
    "        total_frames += dir_frames\n",
    "        frame_stats[training_dir] = {\n",
    "            'videos': len(video_dirs),\n",
    "            'frames': dir_frames\n",
    "        }\n",
    "        \n",
    "        print(f\"   {training_dir}: {len(video_dirs)} videos, {dir_frames} frames\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Summary:\")\n",
    "    print(f\"   Total training directories: {len(training_dirs)}\")\n",
    "    print(f\"   Total videos: {total_videos}\")\n",
    "    print(f\"   Total frames: {total_frames:,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Frames directory not found!\")\n",
    "    frame_stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aafcb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPTIMIZED face extraction functions defined\n",
      "   â€¢ Reduced padding: 10px (vs 20px)\n",
      "   â€¢ Skip already processed videos\n",
      "   â€¢ Faster error handling\n"
     ]
    }
   ],
   "source": [
    "# Optimized Face Extraction Functions\n",
    "def extract_face_from_frame(frame_path, detector, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extract face from a single frame using MTCNN (OPTIMIZED VERSION)\n",
    "    \n",
    "    Args:\n",
    "        frame_path: Path to the frame image\n",
    "        detector: MTCNN detector instance\n",
    "        target_size: Target size for face image\n",
    "    \n",
    "    Returns:\n",
    "        face_img: Processed face image or None if no face found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        image = cv2.imread(frame_path)\n",
    "        if image is None:\n",
    "            return None\n",
    "            \n",
    "        # Convert BGR to RGB for MTCNN\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        result = detector.detect_faces(rgb_image)\n",
    "        \n",
    "        if result:\n",
    "            # Use the first (most confident) face\n",
    "            face = result[0]\n",
    "            x, y, width, height = face['box']\n",
    "            \n",
    "            # OPTIMIZED: Reduced padding from 20 to 10 for speed\n",
    "            padding = 10\n",
    "            x = max(0, x - padding)\n",
    "            y = max(0, y - padding)\n",
    "            width = min(rgb_image.shape[1] - x, width + 2*padding)\n",
    "            height = min(rgb_image.shape[0] - y, height + 2*padding)\n",
    "            \n",
    "            # Extract face region\n",
    "            face_img = rgb_image[y:y+height, x:x+width]\n",
    "            \n",
    "            # Resize to target size\n",
    "            face_resized = cv2.resize(face_img, target_size)\n",
    "            \n",
    "            # Convert back to BGR for saving\n",
    "            face_bgr = cv2.cvtColor(face_resized, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            return face_bgr\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Reduced verbose error logging for speed\n",
    "        pass\n",
    "        \n",
    "    return None\n",
    "\n",
    "def extract_faces_from_video_directory(video_frames_dir, video_faces_dir, detector):\n",
    "    \"\"\"\n",
    "    Extract faces from all frames in a single video directory (OPTIMIZED)\n",
    "    \"\"\"\n",
    "    # SPEED OPTIMIZATION: Check if already processed\n",
    "    if os.path.exists(video_faces_dir):\n",
    "        existing_faces = [f for f in os.listdir(video_faces_dir) if f.endswith('.jpg')]\n",
    "        if len(existing_faces) > 0:\n",
    "            return len(existing_faces)  # Skip if already processed\n",
    "    \n",
    "    Path(video_faces_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    frame_files = sorted([f for f in os.listdir(video_frames_dir) if f.endswith('.jpg')])\n",
    "    extracted_count = 0\n",
    "    \n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(video_frames_dir, frame_file)\n",
    "        face_img = extract_face_from_frame(frame_path, detector, target_face_size)\n",
    "        \n",
    "        if face_img is not None:\n",
    "            face_filename = f\"face_{os.path.splitext(frame_file)[0]}.jpg\"\n",
    "            face_path = os.path.join(video_faces_dir, face_filename)\n",
    "            cv2.imwrite(face_path, face_img)\n",
    "            extracted_count += 1\n",
    "            \n",
    "    return extracted_count\n",
    "\n",
    "print(\"âœ… OPTIMIZED face extraction functions defined\")\n",
    "print(\"   â€¢ Reduced padding: 10px (vs 20px)\")\n",
    "print(\"   â€¢ Skip already processed videos\")\n",
    "print(\"   â€¢ Faster error handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ad1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting OPTIMIZED GPU-Accelerated Face Extraction Pipeline\n",
      "============================================================\n",
      "ðŸ“Š Processing Status:\n",
      "   â€¢ Total directories: 12\n",
      "   â€¢ Already processed: 10\n",
      "   â€¢ Remaining: 2\n",
      "\n",
      "ðŸ”„ RESUME MODE: Starting from 3rd directory onwards...\n",
      "   â€¢ Skipping: ['training80_01', 'training80_02']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07129d629b3b49859c4282e16c09cb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Directories:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ï¸  SKIPPED training80_01: 6966 existing faces\n",
      "â­ï¸  SKIPPED training80_02: 6865 existing faces\n",
      "â­ï¸  SKIPPED training80_02: 6865 existing faces\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe87df0a02c444ca6c171398bb1eb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_03 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_03: 6589 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c2be9d48bd464aa4906d6cc4f0e737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_04 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_04: 6824 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc5511016d54daa84c63f5055ba003e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_05 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_05: 6919 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7619061968574583a29f9f621085c691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_06 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_06: 6856 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420d73968aac413eb15c74f14f16cebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_07 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_07: 6866 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a328af6191584b8f9e67e37da012eb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_08 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_08: 7017 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030bcc4416f9467a88717a881903fc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_09 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_09: 6906 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e117bcdbc12c4ff8af8579f11ca549b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_10 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_10: 6697 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c762efdf2e643c983efa930135c0e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_11 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_11: 6947 faces from 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077332865261424f9a532b0cd67735e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_12 videos:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_12: 6838 faces from 80 videos\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ OPTIMIZED FACE EXTRACTION COMPLETED!\n",
      "============================================================\n",
      "â±ï¸  Processing time: 01:49:29\n",
      "ðŸ˜Š Total faces extracted: 68,459\n",
      "ðŸ“ Videos processed: 800\n",
      "â­ï¸  Directories skipped: 2\n",
      "âŒ Failed videos: 0\n",
      "ðŸŽ¯ GPU acceleration: âœ… Enabled\n",
      "ðŸš€ Speed optimizations: âœ… Enabled\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZED Face Extraction Pipeline with RESUME Functionality\n",
    "print(\"ðŸš€ Starting OPTIMIZED GPU-Accelerated Face Extraction Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "extraction_stats = {\n",
    "    'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'gpu_available': len(tf.config.experimental.list_logical_devices('GPU')) > 0,\n",
    "    'training_directories': {},\n",
    "    'total_faces': 0,\n",
    "    'total_videos_processed': 0,\n",
    "    'failed_videos': [],\n",
    "    'skipped_directories': [],\n",
    "    'optimization_enabled': True\n",
    "}\n",
    "\n",
    "if os.path.exists(frames_base_dir):\n",
    "    training_dirs = sorted([d for d in os.listdir(frames_base_dir) \n",
    "                           if os.path.isdir(os.path.join(frames_base_dir, d))])\n",
    "    \n",
    "    # RESUME FUNCTIONALITY: Check for already processed directories\n",
    "    processed_dirs = []\n",
    "    if os.path.exists(faces_base_dir):\n",
    "        processed_dirs = [d for d in os.listdir(faces_base_dir) \n",
    "                         if os.path.isdir(os.path.join(faces_base_dir, d))]\n",
    "    \n",
    "    print(f\"ðŸ“Š Processing Status:\")\n",
    "    print(f\"   â€¢ Total directories: {len(training_dirs)}\")\n",
    "    print(f\"   â€¢ Already processed: {len(processed_dirs)}\")\n",
    "    print(f\"   â€¢ Remaining: {len(training_dirs) - len(processed_dirs)}\")\n",
    "    \n",
    "    if len(processed_dirs) >= 2:\n",
    "        print(f\"\\nðŸ”„ RESUME MODE: Starting from 3rd directory onwards...\")\n",
    "        print(f\"   â€¢ Skipping: {processed_dirs[:2] if len(processed_dirs) >= 2 else processed_dirs}\")\n",
    "    \n",
    "    # Load existing results if available\n",
    "    if os.path.exists('results/face_extraction_results.json'):\n",
    "        try:\n",
    "            with open('results/face_extraction_results.json', 'r') as f:\n",
    "                previous_stats = json.load(f)\n",
    "                if 'total_faces' in previous_stats:\n",
    "                    extraction_stats['total_faces'] = previous_stats['total_faces']\n",
    "                    extraction_stats['total_videos_processed'] = previous_stats.get('total_videos_processed', 0)\n",
    "                    print(f\"   â€¢ Loaded previous progress: {extraction_stats['total_faces']:,} faces\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Process each training directory\n",
    "    for i, training_dir in enumerate(tqdm(training_dirs, desc=\"Training Directories\")):\n",
    "        training_frames_path = os.path.join(frames_base_dir, training_dir)\n",
    "        training_faces_path = os.path.join(faces_base_dir, training_dir)\n",
    "        \n",
    "        # RESUME LOGIC: Skip first 2 directories if they exist in faces folder\n",
    "        if training_dir in processed_dirs and i < 2:\n",
    "            # Count existing faces for statistics\n",
    "            existing_face_count = 0\n",
    "            if os.path.exists(training_faces_path):\n",
    "                for root, dirs, files in os.walk(training_faces_path):\n",
    "                    existing_face_count += len([f for f in files if f.endswith('.jpg')])\n",
    "            \n",
    "            extraction_stats['skipped_directories'].append({\n",
    "                'directory': training_dir,\n",
    "                'existing_faces': existing_face_count\n",
    "            })\n",
    "            \n",
    "            print(f\"â­ï¸  SKIPPED {training_dir}: {existing_face_count} existing faces\")\n",
    "            continue\n",
    "        \n",
    "        # Get all video directories\n",
    "        video_dirs = sorted([d for d in os.listdir(training_frames_path) \n",
    "                           if os.path.isdir(os.path.join(training_frames_path, d))])\n",
    "        \n",
    "        training_faces = 0\n",
    "        training_failed = 0\n",
    "        \n",
    "        # Process each video directory\n",
    "        for video_dir in tqdm(video_dirs, desc=f\"{training_dir} videos\", leave=False):\n",
    "            video_frames_path = os.path.join(training_frames_path, video_dir)\n",
    "            video_faces_path = os.path.join(training_faces_path, video_dir)\n",
    "            \n",
    "            try:\n",
    "                extracted = extract_faces_from_video_directory(\n",
    "                    video_frames_path, video_faces_path, detector\n",
    "                )\n",
    "                \n",
    "                if extracted > 0:\n",
    "                    training_faces += extracted\n",
    "                    extraction_stats['total_videos_processed'] += 1\n",
    "                else:\n",
    "                    training_failed += 1\n",
    "                    extraction_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {training_dir}/{video_dir}: {e}\")\n",
    "                training_failed += 1\n",
    "                extraction_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "        \n",
    "        # Store training directory stats\n",
    "        extraction_stats['training_directories'][training_dir] = {\n",
    "            'videos_processed': len(video_dirs) - training_failed,\n",
    "            'videos_failed': training_failed,\n",
    "            'faces_extracted': training_faces\n",
    "        }\n",
    "        \n",
    "        extraction_stats['total_faces'] += training_faces\n",
    "        \n",
    "        print(f\"âœ… {training_dir}: {training_faces} faces from {len(video_dirs)} videos\")\n",
    "    \n",
    "    # Calculate processing time\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    extraction_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    extraction_stats['processing_time_seconds'] = processing_time\n",
    "    extraction_stats['processing_time_formatted'] = str(time.strftime('%H:%M:%S', time.gmtime(processing_time)))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸŽ‰ OPTIMIZED FACE EXTRACTION COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"â±ï¸  Processing time: {extraction_stats['processing_time_formatted']}\")\n",
    "    print(f\"ðŸ˜Š Total faces extracted: {extraction_stats['total_faces']:,}\")\n",
    "    print(f\"ðŸ“ Videos processed: {extraction_stats['total_videos_processed']}\")\n",
    "    print(f\"â­ï¸  Directories skipped: {len(extraction_stats['skipped_directories'])}\")\n",
    "    print(f\"âŒ Failed videos: {len(extraction_stats['failed_videos'])}\")\n",
    "    print(f\"ðŸŽ¯ GPU acceleration: {'âœ… Enabled' if extraction_stats['gpu_available'] else 'âŒ Disabled'}\")\n",
    "    print(f\"ðŸš€ Speed optimizations: {'âœ… Enabled' if extraction_stats['optimization_enabled'] else 'âŒ Disabled'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Frames directory not found!\")\n",
    "    extraction_stats['error'] = 'Frames directory not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec19c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Results saved to: results/face_extraction_results.json\n",
      "\n",
      "ðŸ“ˆ Detailed Statistics:\n",
      "----------------------------------------\n",
      "training80_03:\n",
      "  Faces: 6,589\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_04:\n",
      "  Faces: 6,824\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_05:\n",
      "  Faces: 6,919\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_06:\n",
      "  Faces: 6,856\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_07:\n",
      "  Faces: 6,866\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_08:\n",
      "  Faces: 7,017\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_09:\n",
      "  Faces: 6,906\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_10:\n",
      "  Faces: 6,697\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_11:\n",
      "  Faces: 6,947\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "training80_12:\n",
      "  Faces: 6,838\n",
      "  Videos: 80/80 (100.0% success)\n",
      "\n",
      "ðŸš€ Optimization Summary:\n",
      "------------------------------\n",
      "Directories skipped: 2\n",
      "Existing faces counted: 13,831\n",
      "Speed optimizations: MTCNN faster settings, reduced padding, smart resume\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save Optimized Extraction Results\n",
    "results_file = 'results/face_extraction_results.json'\n",
    "\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(extraction_stats, f, indent=2)\n",
    "\n",
    "print(f\"ðŸ“Š Results saved to: {results_file}\")\n",
    "\n",
    "# Display detailed statistics with optimization info\n",
    "print(\"\\nðŸ“ˆ Detailed Statistics:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'training_directories' in extraction_stats:\n",
    "    for training_dir, stats in extraction_stats['training_directories'].items():\n",
    "        success_rate = (stats['videos_processed'] / (stats['videos_processed'] + stats['videos_failed'])) * 100 if (stats['videos_processed'] + stats['videos_failed']) > 0 else 0\n",
    "        print(f\"{training_dir}:\")\n",
    "        print(f\"  Faces: {stats['faces_extracted']:,}\")\n",
    "        print(f\"  Videos: {stats['videos_processed']}/{stats['videos_processed'] + stats['videos_failed']} ({success_rate:.1f}% success)\")\n",
    "        print()\n",
    "\n",
    "# Show optimization summary\n",
    "if 'skipped_directories' in extraction_stats and extraction_stats['skipped_directories']:\n",
    "    print(\"ðŸš€ Optimization Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    total_skipped_faces = sum([item['existing_faces'] for item in extraction_stats['skipped_directories']])\n",
    "    print(f\"Directories skipped: {len(extraction_stats['skipped_directories'])}\")\n",
    "    print(f\"Existing faces counted: {total_skipped_faces:,}\")\n",
    "    print(f\"Speed optimizations: MTCNN faster settings, reduced padding, smart resume\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "396daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPTIMIZED optical flow functions defined with resume capability\n",
      "   â€¢ Original quality parameters restored (pyr_scale=0.5, levels=3, winsize=15, iterations=3)\n",
      "   â€¢ Resume functionality and smart skipping maintained\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZED Optical Flow Computation Functions with Resume Capability\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def compute_optical_flow_for_video_optimized(faces_dir, flow_dir, skip_existing=True):\n",
    "    \"\"\"\n",
    "    OPTIMIZED: Compute optical flow for a sequence of face images in one video\n",
    "    Args:\n",
    "        faces_dir: Directory containing face images\n",
    "        flow_dir: Directory to save optical flow files\n",
    "        skip_existing: Skip if flow files already exist (resume functionality)\n",
    "    Returns:\n",
    "        Number of optical flow computations performed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Path(flow_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get all face images\n",
    "        face_files = sorted([f for f in os.listdir(faces_dir) if f.endswith('.jpg')])\n",
    "        \n",
    "        if len(face_files) < 2:\n",
    "            return 0\n",
    "        \n",
    "        flow_count = 0\n",
    "        skipped_count = 0\n",
    "        \n",
    "        for i in range(len(face_files) - 1):\n",
    "            flow_filename = f\"flow_{i:04d}_{i+1:04d}.npy\"\n",
    "            flow_path = os.path.join(flow_dir, flow_filename)\n",
    "            \n",
    "            # RESUME FUNCTIONALITY: Skip if already exists\n",
    "            if skip_existing and os.path.exists(flow_path):\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Read consecutive frames\n",
    "            frame1_path = os.path.join(faces_dir, face_files[i])\n",
    "            frame2_path = os.path.join(faces_dir, face_files[i + 1])\n",
    "            \n",
    "            frame1 = cv2.imread(frame1_path, cv2.IMREAD_GRAYSCALE)\n",
    "            frame2 = cv2.imread(frame2_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if frame1 is not None and frame2 is not None:\n",
    "                # ORIGINAL PARAMETERS: Higher quality computation (reverted from optimized)\n",
    "                flow = cv2.calcOpticalFlowFarneback(\n",
    "                    frame1, frame2, None,\n",
    "                    pyr_scale=0.5,     # Original value for better quality\n",
    "                    levels=3,          # Original pyramid levels for better quality\n",
    "                    winsize=15,        # Original window size for better quality\n",
    "                    iterations=3,      # Original iterations for better quality\n",
    "                    poly_n=5,          # Keep polynomial expansion\n",
    "                    poly_sigma=1.2,    # Original gaussian for better quality\n",
    "                    flags=0\n",
    "                )\n",
    "                \n",
    "                # Save optical flow as numpy array\n",
    "                np.save(flow_path, flow)\n",
    "                flow_count += 1\n",
    "        \n",
    "        return flow_count, skipped_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing optical flow for {faces_dir}: {e}\")\n",
    "        return 0, 0\n",
    "\n",
    "def load_existing_flow_results():\n",
    "    \"\"\"Load existing optical flow results for resume functionality\"\"\"\n",
    "    flow_results_file = 'results/optical_flow_results.json'\n",
    "    if os.path.exists(flow_results_file):\n",
    "        try:\n",
    "            with open(flow_results_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "    return {\n",
    "        'training_directories': {},\n",
    "        'total_flows': 0,\n",
    "        'total_videos_processed': 0,\n",
    "        'failed_videos': []\n",
    "    }\n",
    "\n",
    "print(\"âœ… OPTIMIZED optical flow functions defined with resume capability\")\n",
    "print(\"   â€¢ Original quality parameters restored (pyr_scale=0.5, levels=3, winsize=15, iterations=3)\")\n",
    "print(\"   â€¢ Resume functionality and smart skipping maintained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b00373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŠ Starting OPTIMIZED Optical Flow Computation with Resume\n",
      "============================================================\n",
      "ðŸ“¥ Loaded existing results: 0 flows already computed\n",
      "Computing optical flow for 12 training directories...\n",
      "ðŸ”„ Resume mode: Will skip existing optical flow files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ffab7fccaf4f4fbb652cd2fda275a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing Optical Flow:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44645c3394644bb98cd6ad9f3b92a4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_01 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_01: +6886 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345365c39e474f1c8ad7115cb6ceeb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_02 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_02: +6785 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48abfeee03ff45109bfdf8267b13e2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_03 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_03: +6509 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1115e79ab0f042d58a3551dd01030e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_04 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_04: +6744 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb74c5c9e9747cf8808caa636dcbfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_05 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_05: +6839 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a5db3a73f34b838abf527540ad3d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_06 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_06: +6776 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f013e9e4ad3d486999a3c2d092d946b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_07 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_07: +6786 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8161865f6f4941843ee1c1dd01bac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_08 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_08: +6937 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b1b8c4576140a49d2482a24596ce0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_09 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_09: +6826 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822a442332b5452b8aab285112a9157d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_10 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_10: +6617 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8d662a4790492ca701ec41960ad3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_11 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_11: +6867 new flows, 0 skipped, 80 videos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fe775f97234970b6eaedc0c4395367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training80_12 optical flow:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… training80_12: +6758 new flows, 0 skipped, 80 videos\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ OPTIMIZED OPTICAL FLOW COMPUTATION COMPLETED!\n",
      "============================================================\n",
      "â±ï¸  Processing time: 00:14:10\n",
      "ðŸŒŠ Total optical flows: 81,330\n",
      "ðŸ†• New flows computed: 81,330\n",
      "â­ï¸  Flows skipped (resume): 0\n",
      "ðŸ“ Videos processed: 960\n",
      "âŒ Failed videos: 0\n"
     ]
    }
   ],
   "source": [
    "# Optical Flow Computation Pipeline\n",
    "print(\"ðŸŒŠ Starting OPTIMIZED Optical Flow Computation with Resume\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "flow_start_time = time.time()\n",
    "\n",
    "# RESUME FUNCTIONALITY: Load existing results\n",
    "existing_flow_stats = load_existing_flow_results()\n",
    "print(f\"ðŸ“¥ Loaded existing results: {existing_flow_stats.get('total_flows', 0)} flows already computed\")\n",
    "\n",
    "flow_stats = {\n",
    "    'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_directories': existing_flow_stats.get('training_directories', {}),\n",
    "    'total_flows': existing_flow_stats.get('total_flows', 0),\n",
    "    'total_videos_processed': existing_flow_stats.get('total_videos_processed', 0),\n",
    "    'failed_videos': existing_flow_stats.get('failed_videos', []),\n",
    "    'optimization_stats': {\n",
    "        'new_flows': 0,\n",
    "        'skipped_flows': 0,\n",
    "        'resume_enabled': True\n",
    "    }\n",
    "}\n",
    "\n",
    "if os.path.exists(faces_base_dir):\n",
    "    training_dirs = sorted([d for d in os.listdir(faces_base_dir)\n",
    "                           if os.path.isdir(os.path.join(faces_base_dir, d))])\n",
    "    \n",
    "    print(f\"Computing optical flow for {len(training_dirs)} training directories...\")\n",
    "    print(f\"ðŸ”„ Resume mode: Will skip existing optical flow files\")\n",
    "    \n",
    "    # Process each training directory\n",
    "    for training_dir in tqdm(training_dirs, desc=\"Computing Optical Flow\"):\n",
    "        training_faces_path = os.path.join(faces_base_dir, training_dir)\n",
    "        training_flow_path = os.path.join(flow_base_dir, training_dir)\n",
    "        \n",
    "        # Get all video directories\n",
    "        video_dirs = sorted([d for d in os.listdir(training_faces_path)\n",
    "                           if os.path.isdir(os.path.join(training_faces_path, d))])\n",
    "        \n",
    "        training_flows = 0\n",
    "        training_skipped = 0\n",
    "        training_failed = 0\n",
    "        \n",
    "        # Check if this training directory was already processed\n",
    "        existing_training_stats = flow_stats['training_directories'].get(training_dir, {})\n",
    "        \n",
    "        # Process each video directory\n",
    "        for video_dir in tqdm(video_dirs, desc=f\"{training_dir} optical flow\", leave=False):\n",
    "            video_faces_path = os.path.join(training_faces_path, video_dir)\n",
    "            video_flow_path = os.path.join(training_flow_path, video_dir)\n",
    "            \n",
    "            try:\n",
    "                flow_count, skipped_count = compute_optical_flow_for_video_optimized(\n",
    "                    video_faces_path, video_flow_path, skip_existing=True\n",
    "                )\n",
    "                \n",
    "                if flow_count > 0 or skipped_count > 0:\n",
    "                    training_flows += flow_count\n",
    "                    training_skipped += skipped_count\n",
    "                    if flow_count > 0:  # Only count as processed if new flows were computed\n",
    "                        flow_stats['total_videos_processed'] += 1\n",
    "                else:\n",
    "                    training_failed += 1\n",
    "                    flow_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error computing optical flow for {training_dir}/{video_dir}: {e}\")\n",
    "                training_failed += 1\n",
    "                flow_stats['failed_videos'].append(f\"{training_dir}/{video_dir}\")\n",
    "        \n",
    "        # Update training directory stats\n",
    "        flow_stats['training_directories'][training_dir] = {\n",
    "            'videos_processed': len(video_dirs) - training_failed,\n",
    "            'videos_failed': training_failed,\n",
    "            'flows_computed': existing_training_stats.get('flows_computed', 0) + training_flows,\n",
    "            'flows_skipped': training_skipped,\n",
    "            'new_flows_this_run': training_flows\n",
    "        }\n",
    "        \n",
    "        flow_stats['total_flows'] += training_flows\n",
    "        flow_stats['optimization_stats']['new_flows'] += training_flows\n",
    "        flow_stats['optimization_stats']['skipped_flows'] += training_skipped\n",
    "        \n",
    "        print(f\"âœ… {training_dir}: +{training_flows} new flows, {training_skipped} skipped, {len(video_dirs)} videos\")\n",
    "        \n",
    "        # SAVE PROGRESS after each training directory (checkpoint)\n",
    "        flow_results_file = 'results/optical_flow_results.json'\n",
    "        with open(flow_results_file, 'w') as f:\n",
    "            json.dump(flow_stats, f, indent=2)\n",
    "    \n",
    "    # Calculate processing time\n",
    "    flow_end_time = time.time()\n",
    "    flow_processing_time = flow_end_time - flow_start_time\n",
    "    flow_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    flow_stats['processing_time_seconds'] = flow_processing_time\n",
    "    flow_stats['processing_time_formatted'] = str(time.strftime('%H:%M:%S', time.gmtime(flow_processing_time)))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸŽ‰ OPTIMIZED OPTICAL FLOW COMPUTATION COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"â±ï¸  Processing time: {flow_stats['processing_time_formatted']}\")\n",
    "    print(f\"ðŸŒŠ Total optical flows: {flow_stats['total_flows']:,}\")\n",
    "    print(f\"ðŸ†• New flows computed: {flow_stats['optimization_stats']['new_flows']:,}\")\n",
    "    print(f\"â­ï¸  Flows skipped (resume): {flow_stats['optimization_stats']['skipped_flows']:,}\")\n",
    "    print(f\"ðŸ“ Videos processed: {flow_stats['total_videos_processed']}\")\n",
    "    print(f\"âŒ Failed videos: {len(flow_stats['failed_videos'])}\")\n",
    "    \n",
    "    # Speed improvement estimation\n",
    "    if flow_stats['optimization_stats']['skipped_flows'] > 0:\n",
    "        estimated_saved_time = flow_stats['optimization_stats']['skipped_flows'] * 0.1  # ~0.1s per flow\n",
    "        print(f\"âš¡ Estimated time saved by resume: {estimated_saved_time:.1f} seconds\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Faces directory not found! Please run face extraction first.\")\n",
    "    flow_stats['error'] = 'Faces directory not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fdd19cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Optical flow results saved to: results/optical_flow_results.json\n",
      "\n",
      "ðŸ“‹ Complete pipeline results saved to: results/complete_preprocessing_results.json\n",
      "\n",
      "======================================================================\n",
      "ðŸ COMPLETE PREPROCESSING PIPELINE SUMMARY\n",
      "======================================================================\n",
      "ðŸ“Š Final Statistics:\n",
      "   â€¢ Total faces extracted: 68,459\n",
      "   â€¢ Total optical flows: 81,330\n",
      "   â€¢ Videos processed: 800\n",
      "   â€¢ GPU acceleration: âœ… Enabled\n",
      "   â€¢ Total pipeline time: 02:03:39\n",
      "\n",
      "ðŸ“ Output Directories:\n",
      "   â€¢ Faces: data/processed/faces\n",
      "   â€¢ Optical Flow: data/processed/optical_flow\n",
      "   â€¢ Results: results/\n",
      "\n",
      "âœ… Preprocessing pipeline completed successfully!\n",
      "   Ready for feature extraction and model training.\n"
     ]
    }
   ],
   "source": [
    "# Save Optical Flow Results\n",
    "flow_results_file = 'results/optical_flow_results.json'\n",
    "\n",
    "with open(flow_results_file, 'w') as f:\n",
    "    json.dump(flow_stats, f, indent=2)\n",
    "\n",
    "print(f\"ðŸ“Š Optical flow results saved to: {flow_results_file}\")\n",
    "\n",
    "# Create Combined Pipeline Summary\n",
    "combined_stats = {\n",
    "    'pipeline_completion_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'gpu_acceleration': len(tf.config.experimental.list_logical_devices('GPU')) > 0,\n",
    "    'face_extraction': extraction_stats if 'extraction_stats' in locals() else {},\n",
    "    'optical_flow': flow_stats if 'flow_stats' in locals() else {}\n",
    "}\n",
    "\n",
    "combined_results_file = 'results/complete_preprocessing_results.json'\n",
    "with open(combined_results_file, 'w') as f:\n",
    "    json.dump(combined_stats, f, indent=2)\n",
    "\n",
    "print(f\"\\nðŸ“‹ Complete pipeline results saved to: {combined_results_file}\")\n",
    "\n",
    "# Display Final Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ COMPLETE PREPROCESSING PIPELINE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'extraction_stats' in locals() and 'flow_stats' in locals():\n",
    "    total_pipeline_time = (extraction_stats.get('processing_time_seconds', 0) + \n",
    "                          flow_stats.get('processing_time_seconds', 0))\n",
    "    \n",
    "    print(f\"ðŸ“Š Final Statistics:\")\n",
    "    print(f\"   â€¢ Total faces extracted: {extraction_stats.get('total_faces', 0):,}\")\n",
    "    print(f\"   â€¢ Total optical flows: {flow_stats.get('total_flows', 0):,}\")\n",
    "    print(f\"   â€¢ Videos processed: {extraction_stats.get('total_videos_processed', 0)}\")\n",
    "    print(f\"   â€¢ GPU acceleration: {'âœ… Enabled' if combined_stats['gpu_acceleration'] else 'âŒ Disabled'}\")\n",
    "    print(f\"   â€¢ Total pipeline time: {time.strftime('%H:%M:%S', time.gmtime(total_pipeline_time))}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ Output Directories:\")\n",
    "    print(f\"   â€¢ Faces: {faces_base_dir}\")\n",
    "    print(f\"   â€¢ Optical Flow: {flow_base_dir}\")\n",
    "    print(f\"   â€¢ Results: results/\")\n",
    "    \n",
    "    print(f\"\\nâœ… Preprocessing pipeline completed successfully!\")\n",
    "    print(f\"   Ready for feature extraction and model training.\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Pipeline incomplete - check error messages above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3d6594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Data Verification\n",
      "==============================\n",
      "âœ… Verification Results:\n",
      "   â€¢ Faces directory: âœ…\n",
      "   â€¢ Optical flow directory: âœ…\n",
      "   â€¢ Total face images: 82,290\n",
      "   â€¢ Total optical flow files: 81,330\n",
      "\n",
      "ðŸŽ¯ Next Steps:\n",
      "   1. Extract static features (ResNet-50 2D CNN) â†’ 512-dim features\n",
      "   2. Extract dynamic features (I3D 3D CNN) â†’ 256-dim features\n",
      "   3. Validate data alignment (960 samples)\n",
      "   4. Begin Cross-Attention CNN model training\n",
      "\n",
      "ðŸ“– Ready to proceed with feature extraction and training!\n"
     ]
    }
   ],
   "source": [
    "# Data Verification and Next Steps\n",
    "print(\"\\nðŸ” Data Verification\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Verify output structure\n",
    "verification_results = {\n",
    "    'faces_directory_exists': os.path.exists(faces_base_dir),\n",
    "    'optical_flow_directory_exists': os.path.exists(flow_base_dir),\n",
    "    'face_count': 0,\n",
    "    'flow_count': 0\n",
    "}\n",
    "\n",
    "if verification_results['faces_directory_exists']:\n",
    "    # Count total faces\n",
    "    for root, dirs, files in os.walk(faces_base_dir):\n",
    "        verification_results['face_count'] += len([f for f in files if f.endswith('.jpg')])\n",
    "\n",
    "if verification_results['optical_flow_directory_exists']:\n",
    "    # Count total optical flow files\n",
    "    for root, dirs, files in os.walk(flow_base_dir):\n",
    "        verification_results['flow_count'] += len([f for f in files if f.endswith('.npy')])\n",
    "\n",
    "print(f\"âœ… Verification Results:\")\n",
    "print(f\"   â€¢ Faces directory: {'âœ…' if verification_results['faces_directory_exists'] else 'âŒ'}\")\n",
    "print(f\"   â€¢ Optical flow directory: {'âœ…' if verification_results['optical_flow_directory_exists'] else 'âŒ'}\")\n",
    "print(f\"   â€¢ Total face images: {verification_results['face_count']:,}\")\n",
    "print(f\"   â€¢ Total optical flow files: {verification_results['flow_count']:,}\")\n",
    "\n",
    "# Next Steps\n",
    "print(f\"\\nðŸŽ¯ Next Steps:\")\n",
    "print(f\"   1. Extract static features (ResNet-50 2D CNN) â†’ 512-dim features\")\n",
    "print(f\"   2. Extract dynamic features (I3D 3D CNN) â†’ 256-dim features\")\n",
    "print(f\"   3. Validate data alignment (960 samples)\")\n",
    "print(f\"   4. Begin Cross-Attention CNN model training\")\n",
    "print(f\"\\nðŸ“– Ready to proceed with feature extraction and training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
